{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plate Detection \n",
    "Younghoon Cho\n",
    "### Dataset Used: \n",
    "https://www.kaggle.com/datasets/gpiosenka/us-license-plates-image-classification/data\n",
    "\n",
    "### Plans for Project\n",
    "1. Normalize from 0 to 1\n",
    "2. expected size (3, w , h) RGB\n",
    "3. Model Choice: *Convolutional Neural Network*\n",
    "4. Train Details\n",
    "    Data Augmentation : Not acceptable because the states are placed in a certain place. <br>\n",
    "    Loss Functon : *Cross Entrophy Loss* <br>\n",
    "    Optimizer : Adam or SGD (haven't chosen yet) <br>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10864"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transforms = v2.Compose([\n",
    "    v2.RandomResizedCrop(size=(128, 128), antialias=True),\n",
    "    transforms.ToTensor(),\n",
    "    v2.Normalize((0.485,), (0.229,)),\n",
    "])\n",
    "\n",
    "# download \n",
    "train_dir = './archive/plates/train'\n",
    "train_dir2 = './archive/new plates/train'\n",
    "\n",
    "valid_dir = './archive/plates/valid'\n",
    "valid_dir2 = './archive/new plates/valid'\n",
    "\n",
    "test_dir = './to/archive/plates/test'\n",
    "test_dir2 = './archive/new plates/test'\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random_state = 1\n",
    "torch.manual_seed(random_state)\n",
    "\n",
    "# Create datasets for plates and new plates\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transforms)\n",
    "train_dataset2 = datasets.ImageFolder(root=train_dir2, transform=transforms)\n",
    "\n",
    "valid_dataset = datasets.ImageFolder(root=valid_dir, transform=transforms)\n",
    "valid_dataset2 = datasets.ImageFolder(root=valid_dir2, transform=transforms)\n",
    "\n",
    "test_dataset = datasets.ImageFolder(root=valid_dir, transform=transforms)\n",
    "test_dataset2 = datasets.ImageFolder(root=valid_dir2, transform=transforms)\n",
    "\n",
    "full_train_dataset = ConcatDataset([train_dataset, train_dataset2])\n",
    "full_valid_dataset = ConcatDataset([valid_dataset,valid_dataset2])\n",
    "full_test_dataset = ConcatDataset([test_dataset,test_dataset2])\n",
    "\n",
    "# Split train size\n",
    "original_train_size = len(full_train_dataset)\n",
    "train_size = int(0.7 * original_train_size)\n",
    "valid_size = int(0.15 * original_train_size)\n",
    "test_size = original_train_size - train_size - valid_size\n",
    "\n",
    "train_dataset, add_valid_dataset, add_test_dataset = random_split(full_train_dataset, [train_size, valid_size, test_size])\n",
    "\n",
    "full_valid_dataset = ConcatDataset([full_valid_dataset,add_valid_dataset])\n",
    "full_test_dataset = ConcatDataset([full_test_dataset,add_test_dataset])\n",
    "\n",
    "# Create data loaders for new plates dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(full_valid_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(full_test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# len(train_loader) # 15521 --> 10864\n",
    "# len(valid_loader) # 530 --> 2858\n",
    "# len(test_loader)  # 530 --> 2859"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original Dataset len()\n",
    "len(train_loader) # 15521\n",
    "len(valid_loader) # 530\n",
    "len(test_loader)  # 530\n",
    "\n",
    "because the dataet is too onesided to train_loader, I have moved 0.15 states each to valid_loader and test_loader\n",
    "\n",
    "| name of data | previous | after resize data |\n",
    "|--------------|----------|-------------------|\n",
    "|train_loader|15521 (93%)| 10864(65.5%)|\n",
    "|valid_loader|530 (3.5%) | 2858 (17.2%) |\n",
    "|test_loader|530 (3.5%) | 2859 (17.2%) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plate_recognize_model(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=25088, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=56, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 126, 126]           1,792\n",
      "         MaxPool2d-2           [-1, 64, 63, 63]               0\n",
      "            Conv2d-3          [-1, 128, 61, 61]          73,856\n",
      "         MaxPool2d-4          [-1, 128, 30, 30]               0\n",
      "            Conv2d-5           [-1, 64, 28, 28]          73,792\n",
      "         MaxPool2d-6           [-1, 64, 14, 14]               0\n",
      "            Linear-7                  [-1, 256]       6,422,784\n",
      "           Dropout-8                  [-1, 256]               0\n",
      "            Linear-9                  [-1, 128]          32,896\n",
      "           Linear-10                   [-1, 56]           7,224\n",
      "================================================================\n",
      "Total params: 6,612,344\n",
      "Trainable params: 6,612,344\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 14.69\n",
      "Params size (MB): 25.22\n",
      "Estimated Total Size (MB): 40.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "class plate_recognize_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Model Structure\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3)\n",
    "        self.conv3 = nn.Conv2d(128, 64, kernel_size=3)\n",
    "\n",
    "        # Pooling layers\n",
    "        self.pool = nn.MaxPool2d(2, 2)  # MaxPooling2D((2, 2))\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(25088 , 256)  # Flatten and Dense(256, activation='relu')\n",
    "        self.fc2 = nn.Linear(256, 128)  # Dense(128, activation='relu')\n",
    "        self.fc3 = nn.Linear(128, 56)   # Dense(56, activation='softmax')\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with ReLU and pooling\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        # Flatten the tensor for fully connected layers\n",
    "        x = x.view(-1, 25088)  # Flatten from (128 * 16 * 28)\n",
    "\n",
    "        # Apply fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Apply softmax activation in the last layer\n",
    "        x = F.softmax(self.fc3(x), dim=1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = plate_recognize_model()\n",
    "\n",
    "# Print the model summary\n",
    "print(model)\n",
    "    \n",
    "summary(model, input_size=(3,128,128))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
